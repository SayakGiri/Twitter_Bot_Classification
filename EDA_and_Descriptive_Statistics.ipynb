{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Importing Packages for the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages required for data manipulation and Feature Engineering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import pylab as py\n",
    "\n",
    "# statistical package for conducting hypothesis tests and other tasks \n",
    "import statsmodels.api as stm\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import norm\n",
    "\n",
    "#package for model building\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "#package for Feature Engeeniring/Categorical Data Transformation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# import SMOTE module from imblearn library \n",
    "# pip install imblearn (if you don't have imblearn in your system) \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# to allow multiple outputs be visible in the same output cell\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data ustilised for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv(\"D:/Sitanshu/Python/Twitter_Bot_Classification/finaldata.csv\")\n",
    "df=pd.read_csv(\"~/virtualenv/Twitter_Project/Twitter_Bot_Classification/finaldata.csv\")\n",
    "#df_1=pd.read_csv(\"D:/Sitanshu/Python/Twitter_Bot_Classification/model_data.csv\")\n",
    "#try to embed features from df_1 in code so that single file is called\n",
    "df_1=pd.read_csv(\"~/virtualenv/Twitter_Project/Twitter_Bot_Classification/model_data.csv\")\n",
    "df_1 = df_1.drop('Unnamed: 0', axis =1)\n",
    "df.drop(['Unnamed: 0', 'crawled_at', 'contributors_enabled','testset', 'random', 'default_profile_image', 'notifications', 'following', 'follow_request_sent', 'is_translator'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Modification for use in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying certain columns to use in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not using df_1 then uncomment\n",
    "\n",
    "# manipulating target variable by putting 0 and 1 values\n",
    "\n",
    "#if the account's SPAM/Bot label it 1, else label it 0.\n",
    "df.loc[df[\"Category\"] == 'genuine', \"class\"] = \"0\"\n",
    "df.loc[df[\"Category\"] != 'genuine', \"class\"] = \"1\"\n",
    "#class count\n",
    "df['class'].value_counts()\n",
    "\n",
    "#If url is present in the twitter account label 1, else label 0. \n",
    "df.loc[df[\"url\"].isnull(), \"url_present\"] = \"0\"\n",
    "df.loc[df[\"url\"].notnull(), \"url_present\"] = \"1\"\n",
    "#count of accounts\n",
    "df['url_present'].value_counts()\n",
    "#bar plot to visualise the class of account based on url_present label\n",
    "#fig_1 = sns.countplot(x = 'url_present', data = df, hue = 'class')\n",
    "\n",
    "#if the profile is default or not, bot/SPAM accounts are likely to be default\n",
    "df.loc[df[\"default_profile\"].isnull(), \"default_profile\"] = \"0\"\n",
    "#default account value count based on the label\n",
    "df['default_profile'].value_counts()\n",
    "#bar plot to visualise distribution of default_profile on class\n",
    "#fig_1 = sns.countplot(x = 'default_profile', data = df, hue = 'class')\n",
    "\n",
    "#if the account has enabled it's geo location\n",
    "df.loc[df[\"geo_enabled\"].isnull(), \"geo_enabled\"] = \"0\"\n",
    "#count of accounts that have enabled their geo_location\n",
    "df['geo_enabled'].value_counts()\n",
    "#visualisation\n",
    "#fig_1 = sns.countplot(x = 'geo_enabled', data = df, hue = 'class')\n",
    "\n",
    "df.loc[df[\"profile_use_background_image\"].isnull(), \"profile_use_background_image\"] = \"0\"\n",
    "df['profile_use_background_image'].value_counts()\n",
    "#fig_1 = sns.countplot(x = 'profile_use_background_image', data = df, hue = 'class')\n",
    "\n",
    "df.loc[df[\"description\"].isnull(), \"description_present\"] = \"0\"\n",
    "df.loc[df[\"description\"].notnull(), \"description_present\"] = \"1\"\n",
    "df['description_present'].value_counts()\n",
    "\n",
    "\n",
    "df.loc[df[\"verified\"] != 1, \"verified\"] = \"0\"\n",
    "df['verified'].value_counts()\n",
    "df.loc[df[\"protected\"] != 1, \"protected\"] = \"0\"\n",
    "df['protected'].value_counts()\n",
    "#fig_1 = sns.countplot(x = 'description_present', data = df, hue = 'class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ignore warning should be implemented or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[['screen_name','statuses_count', 'followers_count', 'friends_count', 'favourites_count', 'listed_count', 'url_present', 'default_profile', 'geo_enabled', 'profile_use_background_image','description_present', 'verified', 'protected', 'class']]\n",
    "\n",
    "#implement age variable function in the above portion only directly from the df['timestamp']\n",
    "df_model['age'] = df_1['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using EDA to understand data and create new Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "df_model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = df.corr()\n",
    "sns.set(rc = {'figure.figsize':(10, 10)} )\n",
    "sns.set(font_scale = 2)\n",
    "sns.heatmap(corrMatrix, vmin = -1, vmax = 1, center = 0, cmap = sns.diverging_palette(40, 420, n = 200), square = True, cbar_kws = {'shrink': 1}, annot = True)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list = ['statuses_count', 'followers_count', 'friends_count', 'favourites_count', 'listed_count', 'age']\n",
    "for i in list:\n",
    "    fig = plt.figure(figsize =(7, 7)) \n",
    "    # Creating axes instance \n",
    "    ax = fig.add_axes([1, 1, 1, 1]) \n",
    "    #change of origin by adding 1 to the original data \n",
    "    ax.boxplot(df_model[i] + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list = {'statuses_count', 'followers_count', 'friends_count', 'favourites_count', 'listed_count', 'age'}\n",
    "for i in list:\n",
    "    fig, ax = plt.subplots(1)\n",
    "    sns.histplot(df_model[i], bins = 100, log_scale= False, kde = True)\n",
    "    #np.log(df[i]+1).plot.hist(bins = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list = {'statuses_count', 'followers_count', 'friends_count', 'favourites_count', 'listed_count', 'age'}\n",
    "for i in list:\n",
    "    fig, ax = plt.subplots(1)\n",
    "    sns.histplot(df_model[i]+1, bins = 100, log_scale= True, kde = True)\n",
    "    #np.log(df[i]+1).plot.hist(bins = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#look for details\n",
    "crim_boxcox = stats.boxcox(df['statuses_count']+1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['verified'], df['protected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['default_profile'], df['protected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['default_profile'], df['protected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working with crosstab to assess the suitability of variables\n",
    "#pd.crosstab(df['default_profile'], df['default_profile_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['class'], df['verified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['class'], df['protected'], margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['protected'], df['verified'], margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['verified'], df['class'], margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = pd.crosstab(index = df_model['protected'], columns = df_model['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "cross = pd.crosstab(index = [df_model['verified'], df_model['protected'], df_model['default_profile'], df_model['profile_use_background_image'], df_model['description_present'], df_model['geo_enabled'], df_model['url_present']], columns = df['class'])\n",
    "plt.subplots(figsize=(10,10))\n",
    "plt.tick_params(labelsize = 10)\n",
    "sns.heatmap(cross, cmap = 'YlOrBr', cbar_kws = {'shrink': 0.8})\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairplot = df[['statuses_count', 'followers_count', 'friends_count', 'favourites_count', 'listed_count', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairplot['statuses_count'] = np.log(df_pairplot['statuses_count']+1)\n",
    "df_pairplot['followers_count'] = np.log(df_pairplot['followers_count']+1)\n",
    "df_pairplot['friends_count'] = np.log(df_pairplot['friends_count']+1)\n",
    "df_pairplot['favourites_count'] = np.log(df_pairplot['favourites_count']+1)\n",
    "df_pairplot['listed_count'] = np.log(df_pairplot['listed_count']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_pairplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_pairplot, hue = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D Plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(np.log(df['followers_count']+1), np.log(df['listed_count']+1), np.log(df['favourites_count']+1), c='r', marker='o')\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plot\n",
    "fig = px.scatter_3d(df, x=np.log(df['statuses_count']+1), y=np.log(df['followers_count']+1), z=np.log(df['listed_count']+1),color=df['Category'],labels= True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_5 = stm.qqplot(np.log(df['favourites_count']+1), line = '45')\n",
    "fig_4 = stm.qqplot(np.log(df['listed_count']+1), line = '45')\n",
    "fig_3 = stm.qqplot(np.log(df['followers_count']+1), line = '45')\n",
    "fig_2 = stm.qqplot(np.log(df['statuses_count']+1), line = '45')\n",
    "fig_1 = stm.qqplot(np.log(df['friends_count']+1), line = '45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(df['followers_count']+1), np.log(df['friends_count']+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on this section required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation using Color Schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulating color_codes of the text to create the feature assiciated with background text color. \n",
    "df['profile_background_color'].value_counts()\n",
    "\n",
    "df.loc[df[\"profile_background_color\"] == '0000FF', \"background_color_class\"] = \"0000FF\"\n",
    "df.loc[df[\"profile_background_color\"] == 'C0DEED', \"background_color_class\"] = \"C0DEED\"\n",
    "df.loc[df[\"profile_background_color\"] == '131516', \"background_color_class\"] = \"131516\"\n",
    "df.loc[df[\"profile_background_color\"] == '000000', \"background_color_class\"] = \"000000\"\n",
    "df.loc[df['background_color_class'].isnull(), 'background_color_class'] = \"others\"\n",
    "df['background_color_class'].value_counts()\n",
    "fig_1 = sns.countplot(x = 'background_color_class', data = df, hue = 'class')\n",
    "#df.loc[np.logical_and(df[\"profile_background_color\"] != '131516', df[\"profile_background_color\"] != 'C0DEED',df[\"profile_background_color\"] != '0000FF') , \"background_color_class\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['profile_text_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Need to change variable encoding for 0  and 000000, since 0 represents missing value and is category in itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulating target variable by putting 0 and 1 values\n",
    "df.loc[df[\"profile_text_color\"] == '333333', \"text_color_class\"] = \"333333\"\n",
    "df.loc[np.logical_or(df[\"profile_text_color\"] == '0',df[\"profile_text_color\"] == '000000') , \"text_color_class\"] = \"000000\"\n",
    "df.loc[df[\"profile_text_color\"] == '3D1957', \"text_color_class\"] = \"3\"\n",
    "#df.loc[np.logical_and(df[\"profile_background_color\"] != '131516', df[\"profile_background_color\"] != 'C0DEED',df[\"profile_background_color\"] != '0000FF') , \"background_color_class\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_color_class'] = df['text_color_class'].fillna(\"other\")\n",
    "df['text_color_class'].value_counts()\n",
    "fig_1 = sns.countplot(x = 'background_color_class', data = df, hue = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['text_color_class'] = df['text_color_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['profile_sidebar_fill_color'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulating target variable by putting 0 and 1 values\n",
    "df.loc[df[\"profile_sidebar_fill_color\"] == 'DDEEF6', \"sidebar_color_class\"] = \"DDEEF6\"\n",
    "df.loc[np.logical_or(df[\"profile_sidebar_fill_color\"] == '0',df[\"profile_sidebar_fill_color\"] == '000000') , \"sidebar_color_class\"] = \"000000\"\n",
    "df.loc[df[\"profile_sidebar_fill_color\"] == '407DB0', \"sidebar_color_class\"] = \"407DB0\"\n",
    "df.loc[df[\"profile_sidebar_fill_color\"] == 'EFEFEF', \"sidebar_color_class\"] = \"EFEFEF\"\n",
    "#df.loc[np.logical_and(df[\"profile_background_color\"] != '131516', df[\"profile_background_color\"] != 'C0DEED',df[\"profile_background_color\"] != '0000FF') , \"background_color_class\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sidebar_color_class'] = df['sidebar_color_class'].fillna('others')\n",
    "#fig_1 = sns.countplot(x = 'sidebar_color_class', data = df, hue = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['sidebar_color_class'] = df['sidebar_color_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing and significance of Variable, assumptions of Hypothesis Tests are to be met before performing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing of hypothesis that newly created variables have significant impact on the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are using training data to set variables, we may not find the variable highly effective in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-test-for-statistically-significant-relationships-between-categorical-variables-with-chi-66c3ebeda7cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create column with value count of class for the pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hypothesis: variables 'protected and class are independent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, ex = chi2_contingency(pivot_df, correction=False)\n",
    "print(chi2, '{:.10f}'.format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hypothesis: variables 'background_color_class and class are independent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = pd.crosstab(index = df_model['background_color_class'], columns = df_model['class'])\n",
    "\n",
    "chi2, p, dof, ex = chi2_contingency(pivot_df, correction=True)\n",
    "print(pivot_df)\n",
    "print(chi2, '{:.10f}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Variable Encoding for Categorical Variables and Creates features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for nominal data \n",
    "gle = LabelEncoder()\n",
    "s_color_labels = gle.fit_transform(df_model['sidebar_color_class'])\n",
    "s_color_mappings = {index: label for index, label in \n",
    "                  enumerate(gle.classes_)}\n",
    "s_color_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_model['s_color_labels'] = s_color_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ohe = OneHotEncoder()\n",
    "s_color_f_arr = gen_ohe.fit_transform(\n",
    "                              df_model[['s_color_labels']]).toarray()\n",
    "feature_labels = list(gle.classes_)\n",
    "gen_features = pd.DataFrame(s_color_f_arr, \n",
    "                            columns=feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_1 = pd.concat([df_model.reset_index(drop=True), gen_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_1.drop(labels = ['s_color_labels', 'sidebar_color_class', 'text_color_class', 'background_color_class'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics model Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_1 = df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_1['url_present'] = df_model_1['url_present'].astype(float)\n",
    "df_model_1['default_profile'] = df_model_1['default_profile'].astype(float)\n",
    "df_model_1['geo_enabled'] = df_model_1['geo_enabled'].astype(float)\n",
    "df_model_1['profile_use_background_image'] = df_model_1['profile_use_background_image'].astype(float)\n",
    "df_model_1['description_present'] = df_model_1['description_present'].astype(float)\n",
    "df_model_1['verified'] = df_model_1['verified'].astype(float)\n",
    "df_model_1['protected'] = df_model_1['protected'].astype(float)\n",
    "df_model_1['class'] = df_model_1['class'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "X=df_model_1.drop(columns = ['class', 'screen_name'], axis =1)\n",
    "#target variable\n",
    "y=df_model_1[['class']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 70:30 ration \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) \n",
    "\n",
    "# describes info about train and test set \n",
    "print(\"Number transactions X_train dataset: \", X_train.shape) \n",
    "print(\"Number transactions y_train dataset: \", y_train.shape) \n",
    "print(\"Number transactions X_test dataset: \", X_test.shape) \n",
    "print(\"Number transactions y_test dataset: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on train set\n",
    "lr1 = LogisticRegression() \n",
    "fit_model = lr1.fit(X_train, y_train)\n",
    "predictions = lr1.predict(X_test) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Oversampling technique to increase the label count for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
    "\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel()) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on train set\n",
    "lr1 = LogisticRegression() \n",
    "fit_model = lr1.fit(X_train_res, y_train_res)\n",
    "predictions = lr1.predict(X_test) \n",
    "\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling to assess the model accuracy when less data is present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before Undersampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before Undersampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
    "\n",
    "# apply near miss \n",
    "from imblearn.under_sampling import NearMiss \n",
    "nr = NearMiss() \n",
    "\n",
    "X_train_miss, y_train_miss = nr.fit_resample(X_train, y_train.ravel()) \n",
    "\n",
    "print('After Undersampling, the shape of train_X: {}'.format(X_train_miss.shape)) \n",
    "print('After Undersampling, the shape of train_y: {} \\n'.format(y_train_miss.shape)) \n",
    "\n",
    "print(\"After Undersampling, counts of label '1': {}\".format(sum(y_train_miss == 1))) \n",
    "print(\"After Undersampling, counts of label '0': {}\".format(sum(y_train_miss == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model on train set \n",
    "lr2 = LogisticRegression() \n",
    "lr2.fit(X_train_miss, y_train_miss) \n",
    "predictions = lr2.predict(X_test) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model on log transformed data (variables with large range) and checking if it improves the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# log transformation of variables with large values for better fitting of model.\n",
    "\n",
    "X = (pd.DataFrame([np.log(X['statuses_count']+1), np.log(X['followers_count']+1), np.log(X['friends_count']+1), np.log(X['favourites_count']+1), np.log(X['listed_count']+1), X['default_profile'], X['geo_enabled'], X['verified'], X['protected'], X['profile_use_background_image'], X['url_present'], X['description_present'], X['age']]))\n",
    "X = np.transpose(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 70:30 ration \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) \n",
    "\n",
    "# describes info about train and test set \n",
    "print(\"Number transactions X_train dataset: \", X_train.shape) \n",
    "print(\"Number transactions y_train dataset: \", y_train.shape) \n",
    "print(\"Number transactions X_test dataset: \", X_test.shape) \n",
    "print(\"Number transactions y_test dataset: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on train set\n",
    "lr1 = LogisticRegression() \n",
    "fit_model = lr1.fit(X_train, y_train)\n",
    "predictions = lr1.predict(X_test) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using statsmodel package to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/logistic-regression-using-statsmodels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = stm.Logit(y_train, X_train).fit()\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_1 = stm.GLM(y_train, X_train).fit()\n",
    "print(log_reg_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE\n",
    "##### RFE for the top features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(logreg, 1)\n",
    "\n",
    "rfe = rfe.fit(X, y)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = X_train\n",
    "selector = RFE(lr1, n_features_to_select= 1)\n",
    "selector = selector.fit(predictors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = selector.ranking_\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranks = []\n",
    "for i in order:\n",
    "    feature_ranks.append(f\"{i}.{X_train.columns[i-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth = 5, bootstrap=True)\n",
    "model = rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rf, X, y, cv = 6, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binomial Family Model with Default Link Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_model = stm.GLM(y_train, X_train, family = stm.families.Binomial())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_results = bin_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(bin_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work in Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hosmer Lemeshow Test Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hl_test(data, g):\n",
    "    '''\n",
    "    Hosmer-Lemeshow test to judge the goodness of fit for binary data\n",
    "\n",
    "    Input: dataframe(data), integer(num of subgroups divided)\n",
    "    \n",
    "    Output: float\n",
    "    '''\n",
    "    data_st = data.sort_values('prob')\n",
    "    data_st['dcl'] = pd.qcut(data_st['prob'], g)\n",
    "    \n",
    "    ys = data_st['ViolentCrimesPerPop'].groupby(data_st.dcl).sum()\n",
    "    yt = data_st['ViolentCrimesPerPop'].groupby(data_st.dcl).count()\n",
    "    yn = yt - ys\n",
    "    \n",
    "    yps = data_st['prob'].groupby(data_st.dcl).sum()\n",
    "    ypt = data_st['prob'].groupby(data_st.dcl).count()\n",
    "    ypn = ypt - yps\n",
    "    \n",
    "    hltest = ( ((ys - yps)**2 / yps) + ((yn - ypn)**2 / ypn) ).sum()\n",
    "    pval = 1 - chi2.cdf(hltest, g-2)\n",
    "    \n",
    "    df = g-2\n",
    "    \n",
    "    print('\\n HL-chi2({}): {}, p-value: {}\\n'.format(df, hltest, pval))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
